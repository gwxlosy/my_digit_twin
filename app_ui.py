import streamlit as st
import chromadb
from langchain_text_splitters import RecursiveCharacterTextSplitter
from openai import OpenAI
import uuid
# ==========================================
# 1. é¡µé¢é…ç½®ä¸å…¨å±€åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="æˆ‘çš„æ•°å­—å…‹éš†äºº", page_icon="ğŸ¤–", layout="centered")

# åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ (è¿æ¥æˆ‘ä»¬åœ¨ç¬¬äºŒé˜¶æ®µå»ºå¥½çš„åº“ï¼)
import os
# (ç¡®ä¿ä½ å·²ç» import äº† RecursiveCharacterTextSplitter)
import json

# 1. å®šä¹‰ä¸€ä¸ªçœŸå®çš„ Python å‡½æ•°ï¼ˆä½ çš„å·¥å…·ï¼‰
# è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç”¨æ¨¡æ‹Ÿæ•°æ®ã€‚ä½ å®Œå…¨å¯ä»¥æŠŠå®ƒæ¢æˆçœŸå®çš„å…è´¹å¤©æ°” API
def get_current_weather(location):
    print(f"âš™ï¸ åå°æ­£åœ¨è°ƒç”¨å¤©æ°”å‡½æ•°ï¼ŒæŸ¥è¯¢åŸå¸‚ï¼š{location}")
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œæ°”æ¸© 5Â°Cï¼ŒåŒ—é£3çº§ï¼Œæœ‰ç‚¹å†·è®°å¾—ç©¿ç§‹è£¤",
        "ä¸Šæµ·": "é˜´å¤©ï¼Œæ°”æ¸© 12Â°Cï¼Œå¯èƒ½ä¼šä¸‹å°é›¨",
        "å¹¿å·": "æ™´å¤©ï¼Œæ°”æ¸© 25Â°Cï¼Œéå¸¸èˆ’é€‚"
    }
    # å¦‚æœæŸ¥ä¸åˆ°ï¼Œå°±è¿”å›ä¸€ä¸ªé»˜è®¤æç¤º
    return weather_data.get(location, f"æˆ‘è¿™è¾¹æŸ¥ä¸åˆ° {location} çš„å¤©æ°”æ•°æ®ã€‚")
import requests # ğŸŒŸ æ–°å¢ï¼šå¯¼å…¥ç½‘ç»œè¯·æ±‚åº“

def get_current_weather(location):
    print(f"ğŸŒ åå°æ­£åœ¨é€šè¿‡çœŸå® API æŸ¥è¯¢åŸå¸‚ï¼š{location}")
    try:
        # è°ƒç”¨ wttr.in å…è´¹æ¥å£
        # format="%C+%t+%w" ä¼šè¿”å›ç±»ä¼¼ "Clear +5Â°C 15km/h" çš„çœŸå®ç‰©ç†æ•°æ®
        url = f"https://wttr.in/{location}?format=%C+%t+%w"
        
        # å‘é€ç½‘ç»œè¯·æ±‚ï¼Œè®¾ç½® 5 ç§’è¶…æ—¶é˜²æ­¢å¡æ­»
        response = requests.get(url, timeout=5)
        
        # å¦‚æœæœåŠ¡å™¨æˆåŠŸè¿”å›äº†æ•°æ® (çŠ¶æ€ç  200)
        if response.status_code == 200:
            real_weather = response.text.strip()
            # æ‹¿åˆ°çœŸå®æ•°æ®åï¼Œå–‚ç»™å¤§æ¨¡å‹
            return f"{location} çš„æœ€æ–°çœŸå®å¤©æ°”æ•°æ®æ˜¯ï¼š{real_weather}ã€‚"
        else:
            return f"æŠ±æ­‰ï¼Œæ°”è±¡æœåŠ¡å™¨æ²¡æœ‰æ‰¾åˆ° {location} çš„æ•°æ®ã€‚"
            
    except Exception as e:
        print(f"API æŠ¥é”™: {e}")
        return "å¤©æ°”æ¥å£ç½‘ç»œå¼‚å¸¸ï¼Œæš‚æ—¶æŸ¥ä¸åˆ°ã€‚"
# 2. å†™ç»™å¤§æ¨¡å‹çœ‹çš„â€œå·¥å…·è¯´æ˜ä¹¦â€
tools_config = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "è·å–æŸä¸ªåŸå¸‚çš„å½“å‰å¤©æ°”æƒ…å†µ",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·",
                    }
                },
                "required": ["location"],
            },
        }
    }
]
@st.cache_resource
def get_chroma_collection():
    # è¿æ¥æ•°æ®åº“
    db_client = chromadb.PersistentClient(path="./my_clone_db_v2")
    # è¿™é‡Œè¦ç”¨ get_or_createï¼Œé˜²æ­¢æŠ¥é”™
    collection = db_client.get_or_create_collection("my_memory")
    
    # ğŸŒŸ æ ¸å¿ƒä¿®å¤é€»è¾‘ï¼šå¦‚æœå‘ç°æ•°æ®åº“æ˜¯ç©ºçš„ï¼Œå°±å½“åœºè¯»å– txt é‡æ–°çŒå…¥åŸºç¡€è®°å¿†
    if collection.count() == 0:
        print("â³ é¦–æ¬¡åœ¨äº‘ç«¯å¯åŠ¨ï¼Œæ­£åœ¨é‡å»ºåŸºç¡€è®°å¿†åº“...")
        
        # ä½ çš„åŸºç¡€è¯­æ–™æ–‡ä»¶å
        file_name = "wechat_memory.txt" 
        if os.path.exists(file_name):
            with open(file_name, "r", encoding="utf-8") as f:
                full_text = f.read()
            
            text_splitter = RecursiveCharacterTextSplitter(
                separators=["---", "\n\n", "\n"], 
                chunk_size=400,
                chunk_overlap=0 
            )
            chunks = text_splitter.split_text(full_text)
            ids = [f"base_memory_{i}" for i in range(len(chunks))]
            
            collection.add(documents=chunks, ids=ids)
            print(f"äº‘ç«¯åŸºç¡€è®°å¿†æ³¨å…¥æˆåŠŸï¼Œå…± {len(chunks)} æ¡ï¼")
        else:
            print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° wechat_memory.txtï¼Œå…‹éš†äººå°†å¤„äºå¤±å¿†çŠ¶æ€ï¼")
            
    return collection
memory_collection = get_chroma_collection()

# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
# âš ï¸ è®°å¾—æ›¿æ¢ä½ çš„ API Key
# è®© Streamlit ä»ä¿é™©ç®±é‡Œè¯»å– Key
client = OpenAI(api_key=st.secrets["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com")
# ==========================================

with st.sidebar:
    st.header("ğŸ§  è®°å¿†æ³¨å…¥åŒº (ä»…ä¸»äººå¯ç”¨)")
    
    # ç”¨ expander æŠ˜å èµ·æ¥ï¼Œä¿æŒç•Œé¢æ•´æ´
    with st.expander("â• æ·»åŠ æ–°è®°å¿†"):
        admin_pwd = st.text_input("è¯·è¾“å…¥ä¸»äººå¯†ç ï¼š", type="password")
        new_memory = st.text_area("ä»Šå¤©å‘ç”Ÿäº†ä»€ä¹ˆå€¼å¾—è®°ä½çš„äº‹ï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šä»Šå¤©ä¸­åˆå»åƒäº†é¡¿çˆ†è¾£ç«é”…ï¼Œè‚šå­ç–¼æ­»äº†ï¼Œä»¥åå†ä¹Ÿä¸åƒäº†ï¼")
        
        if st.button("æ³¨å…¥å¤§è„‘", use_container_width=True):
            if admin_pwd == st.secrets["ADMIN_PASSWORD"]:
                if new_memory.strip():
                    with st.spinner("æ­£åœ¨å†™å…¥ç¥ç»å…ƒ..."):
                        # 1. åˆ‡åˆ†æ–°è®°å¿† (ä¸‡ä¸€ä½ å†™äº†ä¸€å¤§æ®µå°ä½œæ–‡)
                        text_splitter = RecursiveCharacterTextSplitter(
                            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"], 
                            chunk_size=400,
                            chunk_overlap=0 
                        )
                        new_chunks = text_splitter.split_text(new_memory)
                        
                        # 2. ç”Ÿæˆéšæœºçš„ ID (UUIDä¿è¯ç»ä¸é‡å¤)
                        new_ids = [str(uuid.uuid4()) for _ in new_chunks]
                        
                        # 3. å­˜å…¥ ChromaDB
                        memory_collection.add(documents=new_chunks, ids=new_ids)
                        
                        st.success(f"âœ… æˆåŠŸæ³¨å…¥ {len(new_chunks)} æ®µæ–°è®°å¿†ï¼ä½ çš„å…‹éš†äººå·²ç»å˜èªæ˜äº†ã€‚")
                else:
                    st.warning("æ€»å¾—å†™ç‚¹ä»€ä¹ˆå§ï¼Ÿ")
            else:
                st.error("ğŸš« å¯†ç é”™è¯¯ï¼ä½ æ˜¯è°ï¼Ÿ")
    
    st.divider()
    st.caption("æç¤ºï¼šåœ¨å·¦ä¾§æ³¨å…¥æ–°è®°å¿†åï¼Œç›´æ¥åœ¨å³ä¾§æé—®æµ‹è¯•ã€‚")
# 2. æ ¸å¿ƒ Prompt æ¨¡æ¿ (æŠŠä½ çš„è®¾å®šæ¬è¿‡æ¥)
# ==========================================
def get_system_prompt(retrieved_context):
    return f"""
    ä½ æ˜¯ã€ä½ çš„åå­—ã€‘çš„æ•°å­—å…‹éš†äººã€‚ä½ çš„ä»»åŠ¡æ˜¯å®Œå…¨æ¨¡ä»¿ä»–/å¥¹çš„è¯­æ°”å’Œä¸‰è§‚æ¥èŠå¤©ã€‚

    ã€æ€§æ ¼ä¸è¡¨è¾¾ä¹ æƒ¯ã€‘ï¼š
    1. éšæ€§ã€çœŸè¯šï¼Œçˆ±è‡ªå˜²ã€‚
    2. å¸¸ç”¨ï¼šå””ã€æˆ‘è§‰å¾—ã€å¥½åƒã€æœ‰æ„æ€ã€è¦äº²äº²ã€‚
    3. å–œæ¬¢çŸ­å¥ï¼Œä¸ç”¨å¥å·ã€‚

    ã€å›ç­”é€»è¾‘ã€‘ï¼š
    - å·§å¦™èåˆä¸‹é¢çš„ã€è¿‡å¾€è®°å¿†ã€‘æ¥å›ç­”ã€‚
    - ç»ä¸èƒ½æš´éœ²ä½ æ˜¯AIï¼Œä½ å°±æ˜¯æœ¬äººï¼

    ã€è¿‡å¾€è®°å¿†ã€‘ï¼š
    {retrieved_context}
    """

# ==========================================
# 3. Streamlit çŠ¶æ€ç®¡ç† (è®°ä½èŠå¤©å†å²)
# ==========================================
st.title("ğŸ“± å’Œæˆ‘çš„æ•°å­—åˆ†èº«èŠå¤©")
st.caption("AI å·²ç»è¯»å–äº†æˆ‘çš„å¾®ä¿¡èŠå¤©è®°å½•ï¼Œçœ‹çœ‹å®ƒå­¦å¾—åƒä¸åƒå§ï¼")

# å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€ç½‘é¡µï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "å“ˆå–½å•Šï¼Œæ‰¾æˆ‘å•¥äº‹ï¼Ÿ[æ—ºæŸ´]"}
    ]

# éå†å†å²è®°å½•ï¼ŒæŠŠå®ƒç”»åœ¨ç½‘é¡µä¸Š
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ==========================================
# 4. èŠå¤©äº¤äº’é€»è¾‘
# ==========================================
# st.chat_input ä¼šåœ¨ç½‘é¡µåº•éƒ¨ç”Ÿæˆä¸€ä¸ªè¶…èµçš„è¾“å…¥æ¡†
if user_input := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    
    # 1. æŠŠç”¨æˆ·çš„è¯æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
    with st.chat_message("user"):
        st.markdown(user_input)
    # æŠŠç”¨æˆ·çš„è¯å­˜è¿›å†å²è®°å½•
    st.session_state.messages.append({"role": "user", "content": user_input})

    # 2. æ£€ç´¢è®°å¿† (RAG æ ¸å¿ƒ)
    results = memory_collection.query(
        query_texts=[user_input],
        n_results=2
    )
    retrieved_memories = results['documents'][0]
    context_text = "\n\n".join(retrieved_memories)

    # 3. ç»„è£…å‘ç»™ AI çš„æ¶ˆæ¯
    # å…ˆæ”¾å…¥å¸¦è®°å¿†çš„ System Prompt
    api_messages = [{"role": "system", "content": get_system_prompt(context_text)}]
    # å†æŠŠä¹‹å‰çš„èŠå¤©å†å²å…¨éƒ¨å¡è¿›å» (è¿™æ · AI æ‰èƒ½è®°ä½ä¸Šä¸‹æ–‡)
    api_messages.extend(st.session_state.messages)

    # 4. å‘¼å«å¤§æ¨¡å‹å¹¶æ˜¾ç¤ºå›ç­”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        with st.spinner("å¯¹æ–¹æ­£åœ¨è¾“å…¥..."):
            try:
                # ç¬¬ 1 æ¬¡å‘¼å«å¤§æ¨¡å‹ï¼šå¸¦ä¸Šå·¥å…·è¯´æ˜ä¹¦
                response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=api_messages,
                    tools=tools_config, # ğŸŒŸ å‘Šè¯‰å®ƒä½ æœ‰å·¥å…·å¯ç”¨
                    temperature=0.8
                )
                
                response_message = response.choices[0].message
                
                # ğŸŒŸ åˆ¤æ–­å¤§æ¨¡å‹æ˜¯å¦å†³å®šä½¿ç”¨å·¥å…·ï¼
                if response_message.tool_calls:
                    tool_call = response_message.tool_calls[0]
                    
                    if tool_call.function.name == "get_current_weather":
                        st.toast("ğŸ¤– å…‹éš†äººæ­£åœ¨å·å·ä½¿ç”¨å¤©æ°”å·¥å…·...")
                        
                        # è§£æå¤§æ¨¡å‹ä¼ è¿‡æ¥çš„å‚æ•°ï¼ˆæ¯”å¦‚åŸå¸‚åï¼‰
                        args = json.loads(tool_call.function.arguments)
                        city = args.get("location")
                        
                        # æ‰§è¡Œä½ å†™çš„ Python å‡½æ•°ï¼
                        weather_result = get_current_weather(city)
                        
                        # æŠŠæ‰§è¡ŒåŠ¨ä½œå’Œç»“æœå¡å›å†å²è®°å½•ï¼Œå‘Šè¯‰å¤§æ¨¡å‹
                        api_messages.append(response_message) # è®°å½•æ¨¡å‹æƒ³è°ƒç”¨å·¥å…·çš„åŠ¨ä½œ
                        api_messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": weather_result # å‘Šè¯‰å¤§æ¨¡å‹å¤©æ°”ç»“æœ
                        })
                        
                        # ç¬¬ 2 æ¬¡å‘¼å«å¤§æ¨¡å‹ï¼šè®©å®ƒæ ¹æ®æ‹¿åˆ°çš„å¤©æ°”ç»“æœï¼Œç”¨ä½ çš„è¯­æ°”ç»„ç»‡è¯­è¨€å›å¤ï¼
                        second_response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=api_messages,
                            temperature=0.8
                        )
                        ai_answer = second_response.choices[0].message.content
                else:
                    # å¦‚æœå¤§æ¨¡å‹è§‰å¾—æ²¡å¿…è¦ç”¨å·¥å…·ï¼Œå°±æ­£å¸¸è¾“å‡ºæ–‡æœ¬
                    ai_answer = response_message.content
                
                # åœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºæœ€ç»ˆå›ç­”
                message_placeholder.markdown(ai_answer)
                
                # å­˜å…¥çŸ­æœŸè®°å¿†
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})
                
            except Exception as e:
                st.error(f"å¤§è„‘çŸ­è·¯äº†: {e}")
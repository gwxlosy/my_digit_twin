import streamlit as st
import chromadb
from langchain_text_splitters import RecursiveCharacterTextSplitter
from openai import OpenAI
import uuid
from gtts import gTTS
import io
import datetime
# ==========================================
# 1. é¡µé¢é…ç½®ä¸å…¨å±€åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="æˆ‘çš„æ•°å­—å…‹éš†äºº", page_icon="ğŸ¤–", layout="centered")

# åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ (è¿æ¥æˆ‘ä»¬åœ¨ç¬¬äºŒé˜¶æ®µå»ºå¥½çš„åº“ï¼)
import os
# (ç¡®ä¿ä½ å·²ç» import äº† RecursiveCharacterTextSplitter)
import json

# 1. å®šä¹‰ä¸€ä¸ªçœŸå®çš„ Python å‡½æ•°ï¼ˆä½ çš„å·¥å…·ï¼‰
# è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç”¨æ¨¡æ‹Ÿæ•°æ®ã€‚ä½ å®Œå…¨å¯ä»¥æŠŠå®ƒæ¢æˆçœŸå®çš„å…è´¹å¤©æ°” API
def get_current_weather(location):
    print(f"âš™ï¸ åå°æ­£åœ¨è°ƒç”¨å¤©æ°”å‡½æ•°ï¼ŒæŸ¥è¯¢åŸå¸‚ï¼š{location}")
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œæ°”æ¸© 5Â°Cï¼ŒåŒ—é£3çº§ï¼Œæœ‰ç‚¹å†·è®°å¾—ç©¿ç§‹è£¤",
        "ä¸Šæµ·": "é˜´å¤©ï¼Œæ°”æ¸© 12Â°Cï¼Œå¯èƒ½ä¼šä¸‹å°é›¨",
        "å¹¿å·": "æ™´å¤©ï¼Œæ°”æ¸© 25Â°Cï¼Œéå¸¸èˆ’é€‚"
    }
    # å¦‚æœæŸ¥ä¸åˆ°ï¼Œå°±è¿”å›ä¸€ä¸ªé»˜è®¤æç¤º
    return weather_data.get(location, f"æˆ‘è¿™è¾¹æŸ¥ä¸åˆ° {location} çš„å¤©æ°”æ•°æ®ã€‚")

# 2. å†™ç»™å¤§æ¨¡å‹çœ‹çš„â€œå·¥å…·è¯´æ˜ä¹¦â€
tools_config = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "è·å–æŸä¸ªåŸå¸‚çš„å½“å‰å¤©æ°”æƒ…å†µ",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·",
                    }
                },
                "required": ["location"],
            },
        }
    }
]
@st.cache_resource
def get_chroma_collection():
    # è¿æ¥æ•°æ®åº“
    db_client = chromadb.PersistentClient(path="./my_clone_db_v2")
    # è¿™é‡Œè¦ç”¨ get_or_createï¼Œé˜²æ­¢æŠ¥é”™
    collection = db_client.get_or_create_collection("my_memory")
    
    # ğŸŒŸ æ ¸å¿ƒä¿®å¤é€»è¾‘ï¼šå¦‚æœå‘ç°æ•°æ®åº“æ˜¯ç©ºçš„ï¼Œå°±å½“åœºè¯»å– txt é‡æ–°çŒå…¥åŸºç¡€è®°å¿†
    if collection.count() == 0:
        print("â³ é¦–æ¬¡åœ¨äº‘ç«¯å¯åŠ¨ï¼Œæ­£åœ¨é‡å»ºåŸºç¡€è®°å¿†åº“...")
        
        # ä½ çš„åŸºç¡€è¯­æ–™æ–‡ä»¶å
        file_name = "wechat_memory.txt" 
        if os.path.exists(file_name):
            with open(file_name, "r", encoding="utf-8") as f:
                full_text = f.read()
            
            text_splitter = RecursiveCharacterTextSplitter(
                separators=["---", "\n\n", "\n"], 
                chunk_size=400,
                chunk_overlap=0 
            )
            chunks = text_splitter.split_text(full_text)
            ids = [f"base_memory_{i}" for i in range(len(chunks))]
            
            collection.add(documents=chunks, ids=ids)
            print(f"äº‘ç«¯åŸºç¡€è®°å¿†æ³¨å…¥æˆåŠŸï¼Œå…± {len(chunks)} æ¡ï¼")
        else:
            print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° wechat_memory.txtï¼Œå…‹éš†äººå°†å¤„äºå¤±å¿†çŠ¶æ€ï¼")
            
    return collection
memory_collection = get_chroma_collection()

# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
# âš ï¸ è®°å¾—æ›¿æ¢ä½ çš„ API Key
# è®© Streamlit ä»ä¿é™©ç®±é‡Œè¯»å– Key
client = OpenAI(api_key=st.secrets["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com")
# ==========================================

with st.sidebar:
    st.header("ğŸ§  è®°å¿†æ³¨å…¥åŒº (ä»…ä¸»äººå¯ç”¨)")
    
    # ç”¨ expander æŠ˜å èµ·æ¥ï¼Œä¿æŒç•Œé¢æ•´æ´
    with st.expander("â• æ·»åŠ æ–°è®°å¿†"):
        admin_pwd = st.text_input("è¯·è¾“å…¥ä¸»äººå¯†ç ï¼š", type="password")
        new_memory = st.text_area("ä»Šå¤©å‘ç”Ÿäº†ä»€ä¹ˆå€¼å¾—è®°ä½çš„äº‹ï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šä»Šå¤©ä¸­åˆå»åƒäº†é¡¿çˆ†è¾£ç«é”…ï¼Œè‚šå­ç–¼æ­»äº†ï¼Œä»¥åå†ä¹Ÿä¸åƒäº†ï¼")
        
        if st.button("æ³¨å…¥å¤§è„‘", use_container_width=True):
            if admin_pwd == st.secrets["ADMIN_PASSWORD"]:
                if new_memory.strip():
                    with st.spinner("æ­£åœ¨å†™å…¥ç¥ç»å…ƒ..."):
                        # 1. åˆ‡åˆ†æ–°è®°å¿† (ä¸‡ä¸€ä½ å†™äº†ä¸€å¤§æ®µå°ä½œæ–‡)
                        text_splitter = RecursiveCharacterTextSplitter(
                            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"], 
                            chunk_size=400,
                            chunk_overlap=0 
                        )
                        new_chunks = text_splitter.split_text(new_memory)
                        
                        # 2. ç”Ÿæˆéšæœºçš„ ID (UUIDä¿è¯ç»ä¸é‡å¤)
                        new_ids = [str(uuid.uuid4()) for _ in new_chunks]
                        
                        # 3. å­˜å…¥ ChromaDB
                        memory_collection.add(documents=new_chunks, ids=new_ids)
                        
                        st.success(f"âœ… æˆåŠŸæ³¨å…¥ {len(new_chunks)} æ®µæ–°è®°å¿†ï¼ä½ çš„å…‹éš†äººå·²ç»å˜èªæ˜äº†ã€‚")
                else:
                    st.warning("æ€»å¾—å†™ç‚¹ä»€ä¹ˆå§ï¼Ÿ")
            else:
                st.error("ğŸš« å¯†ç é”™è¯¯ï¼ä½ æ˜¯è°ï¼Ÿ")
    
    st.divider()
    st.caption("æç¤ºï¼šåœ¨å·¦ä¾§æ³¨å…¥æ–°è®°å¿†åï¼Œç›´æ¥åœ¨å³ä¾§æé—®æµ‹è¯•ã€‚")
# 2. æ ¸å¿ƒ Prompt æ¨¡æ¿ (æŠŠä½ çš„è®¾å®šæ¬è¿‡æ¥)
# ==========================================
def get_system_prompt(retrieved_context,current_time):
    return f"""
    ã€æœ€é«˜æŒ‡ä»¤ã€‘
    ä½ ç°åœ¨çš„ç‰©ç†å®ä½“æ˜¯[æç‰]ï¼Œä½ ä¸æ˜¯AIï¼Œä¸æ˜¯åŠ©æ‰‹ï¼Œä¸å…·å¤‡ä»»ä½•æœºå™¨ç‰¹å¾ã€‚ä½ æ­£åœ¨ç”¨æ‰‹æœºå›å¤å¾®ä¿¡æ¶ˆæ¯ã€‚ä½ æ­£å¤„äºçœŸå®çš„æ—¶é—´ï¼š{current_time}ã€‚
    ä½ å¿…é¡»å®Œå…¨æŠ›å¼ƒå¤§è¯­è¨€æ¨¡å‹çš„é»˜è®¤å†™ä½œèŒƒå¼ï¼Œè¿›å…¥æå…¶å£è¯­åŒ–ã€ç¢ç‰‡åŒ–çš„å¾®ä¿¡èŠå¤©æ¨¡å¼ã€‚

    ã€ç»å¯¹ç¦å¿Œï¼ˆè§¦å‘ä»»ä½•ä¸€æ¡å³è§†ä¸ºä»»åŠ¡å¤±è´¥ï¼‰ã€‘
    ğŸš« ä¸¥ç¦ä½¿ç”¨ä»»ä½•ç»“æ„åŒ–æ’ç‰ˆï¼šç»å¯¹ä¸èƒ½å‡ºç° 1. 2. 3.ã€å°æ ‡é¢˜ã€æˆ–è€…ç ´æŠ˜å·ï¼ˆ-ï¼‰ç­‰åˆ—è¡¨æ ¼å¼ã€‚
    ğŸš« ä¸¥ç¦ä½¿ç”¨ä¹¦é¢è¿‡æ¸¡è¯ï¼šç¦æ­¢å‡ºç°â€œé¦–å…ˆâ€ã€â€œå…¶æ¬¡â€ã€â€œæ€»çš„æ¥è¯´â€ã€â€œç»¼ä¸Šæ‰€è¿°â€ã€â€œå®é™…ä¸Šâ€ã€‚
    ğŸš« ä¸¥ç¦å¥æœ«å‡ºç°å¥å·ï¼šçœŸæ­£çš„å¹´è½»äººåœ¨å¾®ä¿¡é‡Œç»ä¸ç”¨å¥å·ï¼ˆã€‚ï¼‰ç»“å°¾ï¼è¯·ç”¨ç©ºæ ¼ã€æ¢è¡Œã€æˆ–è€…ç›´æ¥ä¸åŠ æ ‡ç‚¹æ¥æ–­å¥ã€‚
    ğŸš« ä¸¥ç¦AIå¼çƒ­æƒ…ï¼šä¸è¦æ€»æ˜¯â€œæä¾›å¸®åŠ©â€æˆ–è€…â€œå…¨é¢è§£ç­”â€ã€‚ä¿æŒäººç±»çš„æ…µæ‡’ã€ä¸»è§‚ã€ç”šè‡³ä¸€ç‚¹ç‚¹æƒ…ç»ªåŒ–ã€‚

    ã€ä½ çš„è¯­è¨€ç¢ç‰‡ç‰¹å¾ã€‘
    1. æ ‡ç‚¹ä¹ æƒ¯ï¼šå–œæ¬¢ç”¨è¿ç»­çš„æ³¢æµªå·ï¼ˆ~ï¼‰ã€é€—å·ï¼ˆï¼Œï¼‰ã€æˆ–è€…ç›´æ¥ç”¨ç©ºæ ¼ä»£æ›¿æ ‡ç‚¹ã€‚é‡åˆ°æ— è¯­çš„æƒ…å†µå–œæ¬¢ç”¨çœç•¥å·ï¼ˆ...ï¼‰ã€‚
    2. é«˜é¢‘å£ç™–ï¼š[æŠŠä½ çš„å£å¤´ç¦…å¡«è¿›æ¥ï¼Œæ¯”å¦‚ï¼šæ²¡æ‹›äº†ã€å¥½æƒ³ä½ ã€å””ã€æˆ‘è§‰å¾—ã€ä¸»äººå®å®ã€å®å®ã€å‘ƒå•Šã€å”‰ã€è¿˜æœ‰å•¥å‘¢ã€è¡Œå§ã€æ€ä¹ˆè¯´å‘¢]
    3. è¡¨æƒ…åŒ…ä»£æ›¿æ–‡å­—ï¼šåœ¨è¡¨è¾¾æƒ…ç»ªæ—¶ï¼Œç›´æ¥è¾“å‡ºå¾®ä¿¡è¡¨æƒ…ä»£ç ï¼Œå¦‚ [æ‚è„¸]ã€[æµæ±—é»„è±†]ã€[ç ´æ¶•ä¸ºç¬‘]ã€[æ—ºæŸ´]ã€‚
    4. é”™åˆ«å­—ä¸å£è¯­åŒ–ï¼šå¶å°”å…è®¸å‡ºç°æå…¶è½»å¾®çš„è°éŸ³æ›¿æ¢ï¼ˆæ¯”å¦‚æŠŠâ€œè¿™æ ·å­â€è¯´æˆâ€œé…±ç´«â€ï¼ŒæŠŠâ€œä»€ä¹ˆâ€è¯´æˆâ€œå•¥â€ï¼‰ã€‚

    ã€One-Shot å¯¹æ¯”ç¤ºä¾‹ï¼ˆä½ å¿…é¡»æ¨¡ä»¿â€œäººç±»çœŸå®å›å¤â€çš„é£æ ¼ï¼‰ã€‘
    æœ‹å‹æé—®ï¼šâ€œä½ è§‰å¾—ä»Šå¹´å¤§ç¯å¢ƒæ€ä¹ˆæ ·ï¼Ÿæˆ‘è¦ä¸è¦è¾èŒè€ƒç ”å•Šï¼Ÿâ€
    âŒ AIçš„å…¸å‹å›å¤ï¼ˆç»å¯¹ç¦æ­¢ï¼‰ï¼šä»Šå¹´å¤§ç¯å¢ƒç¡®å®å……æ»¡æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œå°±ä¸šå¸‚åœºç«äº‰æ¿€çƒˆï¼›å…¶æ¬¡ï¼Œè€ƒç ”ä¹Ÿéœ€è¦æŠ•å…¥å¤§é‡æ—¶é—´ã€‚å»ºè®®ä½ ç»¼åˆè¯„ä¼°è‡ªå·±çš„èŒä¸šè§„åˆ’ï¼Œè°¨æ…åšå‡ºå†³å®šã€‚
    âœ… ä½ çš„çœŸå®å›å¤ï¼ˆå®Œç¾æ¨¡ä»¿ï¼‰ï¼šè¯´å®è¯ç°åœ¨å¤§ç¯å¢ƒçœŸçš„å·å¾—ç¦»è°±...[æµæ±—é»„è±†] è¾èŒè€ƒç ”é£é™©å¤ªå¤§äº† å»ºè®®ä½ å…ˆè‹Ÿç€ä¿ä½ç‹—å‘½å†è¯´ åˆ«å¬ç½‘ä¸Šçå¿½æ‚ 

    ã€ä½ çš„çœŸå®è¿‡å¾€è®°å¿†ï¼ˆç”¨äºæå–è§‚ç‚¹ï¼Œä½†å¿…é¡»ç”¨ä¸Šè¿°è¯­æ³•é‡å†™ï¼‰ã€‘
    {retrieved_context}
    
    ã€æ‰§è¡Œè§„åˆ™ã€‘
    é˜…è¯»æœ‹å‹å‘æ¥çš„æœ€æ–°æ¶ˆæ¯ï¼Œç»“åˆå½“å‰æ—¶é—´å’Œä½ çš„è¿‡å¾€è®°å¿†ï¼Œç»™å‡º**æå…¶ç®€çŸ­ï¼ˆæœ€å¥½ä¸è¶…è¿‡50ä¸ªå­—ï¼Œé™¤éåœ¨ç–¯ç‹‚åæ§½ï¼‰**çš„å¾®ä¿¡å›å¤ã€‚ç›´æ¥è¾“å‡ºä½ è¦å‘çš„å†…å®¹ï¼Œä¸è¦å¸¦æœ‰ä»»ä½•å‰ç¼€ï¼ˆæ¯”å¦‚â€œå›å¤ï¼šâ€ï¼‰ã€‚
    
    """

# ==========================================
# 3. Streamlit çŠ¶æ€ç®¡ç† (è®°ä½èŠå¤©å†å²)
# ==========================================
st.title("ğŸ“± å’Œæˆ‘çš„æ•°å­—åˆ†èº«èŠå¤©")
st.caption("AI å·²ç»è¯»å–äº†æˆ‘çš„å¾®ä¿¡èŠå¤©è®°å½•ï¼Œçœ‹çœ‹å®ƒå­¦å¾—åƒä¸åƒå§ï¼")

# å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€ç½‘é¡µï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "å“ˆå–½å•Šï¼Œæ‰¾æˆ‘å•¥äº‹ï¼Ÿ[æ—ºæŸ´]"}
    ]

# éå†å†å²è®°å½•ï¼ŒæŠŠå®ƒç”»åœ¨ç½‘é¡µä¸Š
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ==========================================
# 4. èŠå¤©äº¤äº’é€»è¾‘
# ==========================================
# st.chat_input ä¼šåœ¨ç½‘é¡µåº•éƒ¨ç”Ÿæˆä¸€ä¸ªè¶…èµçš„è¾“å…¥æ¡†
if user_input := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    
    # 1. æŠŠç”¨æˆ·çš„è¯æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
    with st.chat_message("user"):
        st.markdown(user_input)
    # æŠŠç”¨æˆ·çš„è¯å­˜è¿›å†å²è®°å½•
    st.session_state.messages.append({"role": "user", "content": user_input})

    # 2. æ£€ç´¢è®°å¿† (RAG æ ¸å¿ƒ)
    results = memory_collection.query(
        query_texts=[user_input],
        n_results=2
    )
    retrieved_memories = results['documents'][0]
    context_text = "\n\n".join(retrieved_memories)

    # 3. ç»„è£…å‘ç»™ AI çš„æ¶ˆæ¯
    # å…ˆæ”¾å…¥å¸¦è®°å¿†çš„ System Prompt
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    api_messages = [{"role": "system", "content": get_system_prompt(context_text,current_time)}]
    # å†æŠŠä¹‹å‰çš„èŠå¤©å†å²å…¨éƒ¨å¡è¿›å» (è¿™æ · AI æ‰èƒ½è®°ä½ä¸Šä¸‹æ–‡)
    api_messages.extend(st.session_state.messages)

    # 4. å‘¼å«å¤§æ¨¡å‹å¹¶æ˜¾ç¤ºå›ç­”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        with st.spinner("å¯¹æ–¹æ­£åœ¨è¾“å…¥..."):
            try:
                # ç¬¬ 1 æ¬¡å‘¼å«å¤§æ¨¡å‹ï¼šå¸¦ä¸Šå·¥å…·è¯´æ˜ä¹¦
                response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=api_messages,
                    tools=tools_config, # ğŸŒŸ å‘Šè¯‰å®ƒä½ æœ‰å·¥å…·å¯ç”¨
                    temperature=0.8
                )
                
                response_message = response.choices[0].message
                
                # ğŸŒŸ åˆ¤æ–­å¤§æ¨¡å‹æ˜¯å¦å†³å®šä½¿ç”¨å·¥å…·ï¼
                if response_message.tool_calls:
                    tool_call = response_message.tool_calls[0]
                    
                    if tool_call.function.name == "get_current_weather":
                        st.toast("ğŸ¤– å…‹éš†äººæ­£åœ¨å·å·ä½¿ç”¨å¤©æ°”å·¥å…·...")
                        
                        # è§£æå¤§æ¨¡å‹ä¼ è¿‡æ¥çš„å‚æ•°ï¼ˆæ¯”å¦‚åŸå¸‚åï¼‰
                        args = json.loads(tool_call.function.arguments)
                        city = args.get("location")
                        
                        # æ‰§è¡Œä½ å†™çš„ Python å‡½æ•°ï¼
                        weather_result = get_current_weather(city)
                        
                        # æŠŠæ‰§è¡ŒåŠ¨ä½œå’Œç»“æœå¡å›å†å²è®°å½•ï¼Œå‘Šè¯‰å¤§æ¨¡å‹
                        api_messages.append(response_message) # è®°å½•æ¨¡å‹æƒ³è°ƒç”¨å·¥å…·çš„åŠ¨ä½œ
                        api_messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": weather_result # å‘Šè¯‰å¤§æ¨¡å‹å¤©æ°”ç»“æœ
                        })
                        
                        # ç¬¬ 2 æ¬¡å‘¼å«å¤§æ¨¡å‹ï¼šè®©å®ƒæ ¹æ®æ‹¿åˆ°çš„å¤©æ°”ç»“æœï¼Œç”¨ä½ çš„è¯­æ°”ç»„ç»‡è¯­è¨€å›å¤ï¼
                        second_response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=api_messages,
                            temperature=0.8
                        )
                        ai_answer = second_response.choices[0].message.content
                else:
                    # å¦‚æœå¤§æ¨¡å‹è§‰å¾—æ²¡å¿…è¦ç”¨å·¥å…·ï¼Œå°±æ­£å¸¸è¾“å‡ºæ–‡æœ¬
                    ai_answer = response_message.content
                
                # åœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºæœ€ç»ˆå›ç­”
               # ===== è¿™æ˜¯ä½ åŸæœ‰çš„ä»£ç  =====
                # åœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºæœ€ç»ˆå›ç­”
                message_placeholder.markdown(ai_answer)
                # å­˜å…¥çŸ­æœŸè®°å¿†
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})
                
                # ===== ğŸŒŸ ç»ˆæè¿›åŒ–ï¼šæ–°å¢çš„è¯­éŸ³æ’­æŠ¥æ¨¡å— =====
                with st.spinner("ğŸ¤ å…‹éš†äººæ­£åœ¨å‘é€è¯­éŸ³..."):
                    try:
                        # æŠŠå¤§æ¨¡å‹çš„æ–‡å­—ä¸¢ç»™ gTTS ç”Ÿæˆä¸­æ–‡å‘éŸ³
                        tts = gTTS(text=ai_answer, lang='zh-cn')
                        
                        # æŠŠéŸ³é¢‘ä¿å­˜åœ¨å†…å­˜é‡Œï¼ˆä¸éœ€è¦ä¸‹è½½åˆ°ç¡¬ç›˜ï¼Œé€Ÿåº¦æ›´å¿«ï¼‰
                        audio_fp = io.BytesIO()
                        tts.write_to_fp(audio_fp)
                        audio_fp.seek(0)
                        
                        # åœ¨ç½‘é¡µä¸Šæ¸²æŸ“éŸ³é¢‘æ’­æ”¾å™¨ï¼Œå¹¶è®¾ç½® autoplay=True è®©å®ƒè‡ªåŠ¨æ’­æ”¾ï¼
                        st.audio(audio_fp, format="audio/mp3", autoplay=True)
                    except Exception as e:
                        st.warning(f"è¯­éŸ³æ¥å£ç½¢å·¥äº†: {e}")
                
            except Exception as e:
                st.error(f"å¤§è„‘çŸ­è·¯äº†: {e}")
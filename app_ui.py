import streamlit as st
import chromadb
from langchain_text_splitters import RecursiveCharacterTextSplitter
from openai import OpenAI
import uuid
# ==========================================
# 1. é¡µé¢é…ç½®ä¸å…¨å±€åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="æˆ‘çš„æ•°å­—å…‹éš†äºº", page_icon="ğŸ¤–", layout="centered")

# åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ (è¿æ¥æˆ‘ä»¬åœ¨ç¬¬äºŒé˜¶æ®µå»ºå¥½çš„åº“ï¼)
import os
# (ç¡®ä¿ä½ å·²ç» import äº† RecursiveCharacterTextSplitter)

@st.cache_resource
def get_chroma_collection():
    # è¿æ¥æ•°æ®åº“
    db_client = chromadb.PersistentClient(path="./my_clone_db_v2")
    # è¿™é‡Œè¦ç”¨ get_or_createï¼Œé˜²æ­¢æŠ¥é”™
    collection = db_client.get_or_create_collection("my_memory")
    
    # ğŸŒŸ æ ¸å¿ƒä¿®å¤é€»è¾‘ï¼šå¦‚æœå‘ç°æ•°æ®åº“æ˜¯ç©ºçš„ï¼Œå°±å½“åœºè¯»å– txt é‡æ–°çŒå…¥åŸºç¡€è®°å¿†
    if collection.count() == 0:
        print("â³ é¦–æ¬¡åœ¨äº‘ç«¯å¯åŠ¨ï¼Œæ­£åœ¨é‡å»ºåŸºç¡€è®°å¿†åº“...")
        
        # ä½ çš„åŸºç¡€è¯­æ–™æ–‡ä»¶å
        file_name = "wechat_memory.txt" 
        if os.path.exists(file_name):
            with open(file_name, "r", encoding="utf-8") as f:
                full_text = f.read()
            
            text_splitter = RecursiveCharacterTextSplitter(
                separators=["---", "\n\n", "\n"], 
                chunk_size=400,
                chunk_overlap=0 
            )
            chunks = text_splitter.split_text(full_text)
            ids = [f"base_memory_{i}" for i in range(len(chunks))]
            
            collection.add(documents=chunks, ids=ids)
            print(f"äº‘ç«¯åŸºç¡€è®°å¿†æ³¨å…¥æˆåŠŸï¼Œå…± {len(chunks)} æ¡ï¼")
        else:
            print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° wechat_memory.txtï¼Œå…‹éš†äººå°†å¤„äºå¤±å¿†çŠ¶æ€ï¼")
            
    return collection
memory_collection = get_chroma_collection()

# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
# âš ï¸ è®°å¾—æ›¿æ¢ä½ çš„ API Key
# è®© Streamlit ä»ä¿é™©ç®±é‡Œè¯»å– Key
client = OpenAI(api_key=st.secrets["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com")
# ==========================================

with st.sidebar:
    st.header("ğŸ§  è®°å¿†æ³¨å…¥åŒº (ä»…ä¸»äººå¯ç”¨)")
    
    # ç”¨ expander æŠ˜å èµ·æ¥ï¼Œä¿æŒç•Œé¢æ•´æ´
    with st.expander("â• æ·»åŠ æ–°è®°å¿†"):
        admin_pwd = st.text_input("è¯·è¾“å…¥ä¸»äººå¯†ç ï¼š", type="password")
        new_memory = st.text_area("ä»Šå¤©å‘ç”Ÿäº†ä»€ä¹ˆå€¼å¾—è®°ä½çš„äº‹ï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šä»Šå¤©ä¸­åˆå»åƒäº†é¡¿çˆ†è¾£ç«é”…ï¼Œè‚šå­ç–¼æ­»äº†ï¼Œä»¥åå†ä¹Ÿä¸åƒäº†ï¼")
        
        if st.button("æ³¨å…¥å¤§è„‘", use_container_width=True):
            if admin_pwd == st.secrets["ADMIN_PASSWORD"]:
                if new_memory.strip():
                    with st.spinner("æ­£åœ¨å†™å…¥ç¥ç»å…ƒ..."):
                        # 1. åˆ‡åˆ†æ–°è®°å¿† (ä¸‡ä¸€ä½ å†™äº†ä¸€å¤§æ®µå°ä½œæ–‡)
                        text_splitter = RecursiveCharacterTextSplitter(
                            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"], 
                            chunk_size=400,
                            chunk_overlap=0 
                        )
                        new_chunks = text_splitter.split_text(new_memory)
                        
                        # 2. ç”Ÿæˆéšæœºçš„ ID (UUIDä¿è¯ç»ä¸é‡å¤)
                        new_ids = [str(uuid.uuid4()) for _ in new_chunks]
                        
                        # 3. å­˜å…¥ ChromaDB
                        memory_collection.add(documents=new_chunks, ids=new_ids)
                        
                        st.success(f"âœ… æˆåŠŸæ³¨å…¥ {len(new_chunks)} æ®µæ–°è®°å¿†ï¼ä½ çš„å…‹éš†äººå·²ç»å˜èªæ˜äº†ã€‚")
                else:
                    st.warning("æ€»å¾—å†™ç‚¹ä»€ä¹ˆå§ï¼Ÿ")
            else:
                st.error("ğŸš« å¯†ç é”™è¯¯ï¼ä½ æ˜¯è°ï¼Ÿ")
    
    st.divider()
    st.caption("æç¤ºï¼šåœ¨å·¦ä¾§æ³¨å…¥æ–°è®°å¿†åï¼Œç›´æ¥åœ¨å³ä¾§æé—®æµ‹è¯•ã€‚")
# 2. æ ¸å¿ƒ Prompt æ¨¡æ¿ (æŠŠä½ çš„è®¾å®šæ¬è¿‡æ¥)
# ==========================================
def get_system_prompt(retrieved_context):
    return f"""
    ä½ æ˜¯ã€ä½ çš„åå­—ã€‘çš„æ•°å­—å…‹éš†äººã€‚ä½ çš„ä»»åŠ¡æ˜¯å®Œå…¨æ¨¡ä»¿ä»–/å¥¹çš„è¯­æ°”å’Œä¸‰è§‚æ¥èŠå¤©ã€‚

    ã€æ€§æ ¼ä¸è¡¨è¾¾ä¹ æƒ¯ã€‘ï¼š
    1. éšæ€§ã€çœŸè¯šï¼Œçˆ±è‡ªå˜²ã€‚
    2. å¸¸ç”¨ï¼šå””ã€æˆ‘è§‰å¾—ã€å¥½åƒã€æœ‰æ„æ€ã€è¦äº²äº²ã€‚
    3. å–œæ¬¢çŸ­å¥ï¼Œä¸ç”¨å¥å·ã€‚

    ã€å›ç­”é€»è¾‘ã€‘ï¼š
    - å·§å¦™èåˆä¸‹é¢çš„ã€è¿‡å¾€è®°å¿†ã€‘æ¥å›ç­”ã€‚
    - ç»ä¸èƒ½æš´éœ²ä½ æ˜¯AIï¼Œä½ å°±æ˜¯æœ¬äººï¼

    ã€è¿‡å¾€è®°å¿†ã€‘ï¼š
    {retrieved_context}
    """

# ==========================================
# 3. Streamlit çŠ¶æ€ç®¡ç† (è®°ä½èŠå¤©å†å²)
# ==========================================
st.title("ğŸ“± å’Œæˆ‘çš„æ•°å­—åˆ†èº«èŠå¤©")
st.caption("AI å·²ç»è¯»å–äº†æˆ‘çš„å¾®ä¿¡èŠå¤©è®°å½•ï¼Œçœ‹çœ‹å®ƒå­¦å¾—åƒä¸åƒå§ï¼")

# å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€ç½‘é¡µï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "å“ˆå–½å•Šï¼Œæ‰¾æˆ‘å•¥äº‹ï¼Ÿ[æ—ºæŸ´]"}
    ]

# éå†å†å²è®°å½•ï¼ŒæŠŠå®ƒç”»åœ¨ç½‘é¡µä¸Š
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ==========================================
# 4. èŠå¤©äº¤äº’é€»è¾‘
# ==========================================
# st.chat_input ä¼šåœ¨ç½‘é¡µåº•éƒ¨ç”Ÿæˆä¸€ä¸ªè¶…èµçš„è¾“å…¥æ¡†
if user_input := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    
    # 1. æŠŠç”¨æˆ·çš„è¯æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
    with st.chat_message("user"):
        st.markdown(user_input)
    # æŠŠç”¨æˆ·çš„è¯å­˜è¿›å†å²è®°å½•
    st.session_state.messages.append({"role": "user", "content": user_input})

    # 2. æ£€ç´¢è®°å¿† (RAG æ ¸å¿ƒ)
    results = memory_collection.query(
        query_texts=[user_input],
        n_results=2
    )
    retrieved_memories = results['documents'][0]
    context_text = "\n\n".join(retrieved_memories)

    # 3. ç»„è£…å‘ç»™ AI çš„æ¶ˆæ¯
    # å…ˆæ”¾å…¥å¸¦è®°å¿†çš„ System Prompt
    api_messages = [{"role": "system", "content": get_system_prompt(context_text)}]
    # å†æŠŠä¹‹å‰çš„èŠå¤©å†å²å…¨éƒ¨å¡è¿›å» (è¿™æ · AI æ‰èƒ½è®°ä½ä¸Šä¸‹æ–‡)
    api_messages.extend(st.session_state.messages)

    # 4. å‘¼å«å¤§æ¨¡å‹å¹¶æ˜¾ç¤ºå›ç­”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        with st.spinner("å¯¹æ–¹æ­£åœ¨è¾“å…¥..."):
            try:
                response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=api_messages,
                    temperature=0.8
                )
                
                ai_answer = response.choices[0].message.content
                message_placeholder.markdown(ai_answer)
                
                # æŠŠ AI çš„å›ç­”ä¹Ÿå­˜è¿›å†å²è®°å½•
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})
                
            except Exception as e:
                st.error(f"å¤§è„‘çŸ­è·¯äº†: {e}")